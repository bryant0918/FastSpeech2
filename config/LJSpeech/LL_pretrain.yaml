path:
  ckpt_path: "/emotiv-data-NTX/output/ckpt/LJSpeech/pretrain"
  log_path: "/emotiv-data-NTX/output/log/LJSpeech/pretrain"
  result_path: "/emotiv-data-NTX/output/result/LJSpeech/pretrain"
optimizer:
  batch_size: 32
  betas: [0.9, 0.98]
  eps: 0.000000001
  weight_decay: 0.0
  grad_clip_thresh: 1.0
  grad_acc_step: 1
  warm_up_step: 4000
  anneal_steps: [300000, 400000, 500000]
  anneal_rate: 0.3
d_optimizer:
  d_initial_lr: 0.000001
  d_max_lr: 0.001
  betas: [0.6, 0.998]
step:
  total_step: 900000
  log_step: 200     # 200
  synth_step: 2000  # 2000
  val_step: 2000    # 1000
  save_step: 5000  # 5000
  word_step: 10   # 10
  discriminator_step: 2
pretrain: True
loss:
  pros_weight: 0.5
  pitch_energy_weight: 0.5
  full_duration_weight: 0.01
  label_smoothing: 0.05

# sed -i 's/batch_size: 32/batch_size: 64/' config/LJSpeech/LL_pretrain.yaml